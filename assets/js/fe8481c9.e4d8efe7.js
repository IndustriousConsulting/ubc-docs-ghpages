"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[77],{237:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var s=n(5893),i=n(1151);const a={},r="BTP Document Information Extraction",o={id:"integrations/DIE/documentation",title:"BTP Document Information Extraction",description:"The following documentation describes the implementation of the Document Information Extraction service into the UBC landscape. Document Information Extraction is a OCR (Optical Character Recognition) service of SAPs BTP (Business Technology Platform) enviroment, used to extract machine readable data from different document formats. UBC now provides all the functionalities neccesary to develop a custom process and workflow all the way from a human readable document up to a fully functioning business process.",source:"@site/docs/integrations/DIE/documentation.md",sourceDirName:"integrations/DIE",slug:"/integrations/DIE/documentation",permalink:"/ubc-docs-ghpages/integrations/DIE/documentation",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"ubcSidebar",previous:{title:"S1SEVEN",permalink:"/ubc-docs-ghpages/integrations/S1SEVEN/documentation"},next:{title:"Microsoft Mail",permalink:"/ubc-docs-ghpages/integrations/O365Mail/documentation"}},c={},l=[{value:"1. Document Information Extraction Service",id:"1-document-information-extraction-service",level:2},{value:"1.1 Schema",id:"11-schema",level:3},{value:"1.2 Template",id:"12-template",level:3},{value:"1.3 Extraction",id:"13-extraction",level:3},{value:"2. UBC",id:"2-ubc",level:2},{value:"2.1 Setup",id:"21-setup",level:3},{value:"2.1 Pre extraction processing",id:"21-pre-extraction-processing",level:3},{value:"2.2 Post extraction processing",id:"22-post-extraction-processing",level:3},{value:"3. QEASY implementation",id:"3-qeasy-implementation",level:2},{value:"3.1 Pre extraction processing",id:"31-pre-extraction-processing",level:3},{value:"3.2 Extraction",id:"32-extraction",level:3},{value:"3.3 Post extraction processing",id:"33-post-extraction-processing",level:3},{value:"3.3.1 IDoc creation",id:"331-idoc-creation",level:4},{value:"3.3.2 IDoc mapping",id:"332-idoc-mapping",level:4}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",hr:"hr",img:"img",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"btp-document-information-extraction",children:"BTP Document Information Extraction"}),"\n",(0,s.jsx)(t.p,{children:"The following documentation describes the implementation of the Document Information Extraction service into the UBC landscape. Document Information Extraction is a OCR (Optical Character Recognition) service of SAPs BTP (Business Technology Platform) enviroment, used to extract machine readable data from different document formats. UBC now provides all the functionalities neccesary to develop a custom process and workflow all the way from a human readable document up to a fully functioning business process."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-mermaid",children:'flowchart\n   A["Start your process"] ==> B["Upload documents for extraction"]\n   B ==> C["Get extraction results"]\n   C ==> D["Continue process with extraction results"]\n'})}),"\n",(0,s.jsxs)(t.h2,{id:"1-document-information-extraction-service",children:["1. ",(0,s.jsx)(t.a,{href:"https://help.sap.com/docs/DOCUMENT_INFORMATION_EXTRACTION?locale=en-US",children:"Document Information Extraction Service"})]}),"\n",(0,s.jsx)(t.p,{children:"The Document Information Extraction service is an OCR cloud service that can extract text data from an unstructured document. This data can be queried in a machine-readable format to be used for further processing. The service supports multiple file formats, however we recommend using \u201c.pdf\u201d format. The service comes by default equipped with the ability to process a few standard document types, these are: invoices, purchase orders, payment advice and business cards. In case we choose to process custom document types, a few initial customizing steps are neccesary. The objects to be customized and created will be described in the sections below."}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.h3,{id:"11-schema",children:["1.1 ",(0,s.jsx)(t.a,{href:"https://help.sap.com/docs/DOCUMENT_INFORMATION_EXTRACTION/5fa7265b9ff64d73bac7cec61ee55ae6/020ab638cfa84eb08caa26f5dbf3b8ef.html?locale=en-US",children:"Schema"})]}),"\n",(0,s.jsx)(t.p,{children:"A schema is a collection of potential extraction fields. This can be understood simply as empty variables that are to be filled by the extraction service. We need to define a name and type of the variables. There are only a few possible variable types, number, string, date currency and discount. More important however are the names of these variables, these are used when quering the extracted data as a key-value pair. For this we would recommend using the same name as the target fields in postprocessing, however custom mappings can also be implemented. As standard, header fields are used for data that appears only once per document, line items are to be used for tables."}),"\n",(0,s.jsx)(t.p,{children:'To create a schema, go to the home page of your Document Information Extraction instance, click the settings icon on the lower left side of the screen and click on the "Schema Configuration" option. Here you will have the opportunity to create and maintain schemas.'}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Schema",src:n(6687).Z+"",width:"2158",height:"1612"})}),"\n",(0,s.jsx)(t.p,{children:"As for the naming convention of the schemas we would recommend to use the classic conventions of the customer. The naming convention of the schema fields should be clear and understandable. The best way is to use SAP standard descriptions or some meaningful substitute (for example purchase order number could be \u201cebeln\u201d , \u201cpo_num\u201d )."}),"\n",(0,s.jsxs)(t.h3,{id:"12-template",children:["1.2 ",(0,s.jsx)(t.a,{href:"https://help.sap.com/docs/DOCUMENT_INFORMATION_EXTRACTION/5fa7265b9ff64d73bac7cec61ee55ae6/d044566e8a6646e58a9459079cc30178.html?locale=en-US",children:"Template"})]}),"\n",(0,s.jsx)(t.p,{children:"A template is the next object that needs to be configured. First an already active schema needs to be assigned to a template, so make sure there is already one created and activated. We would suggest defining one schema per process. The reason for this proposal is the automatic template detection functionality of the service, which can automatically assign the correct template to the document based on its layout and schema. So, if we have five different pdf document layouts from which we always extract the same information just from different positions, we only supply the schema, and the service assigns the correct template automatically. Once a schema is assigned, a template can be understood as a map for the extraction service to be able to find the data and fill our extraction fields (based on the assigned schema) for our specific document layout. For custom document layouts the creation of templates is necessary.\nA template also needs an example document to be uploaded with the same layout as the future documents to be processed. On this uploaded example we can then annotate the positions of data to be extracted, each header field and line items of a table. We have to try to be as precise with the annotations as possible. Also keep in mind to choose the best sample document/documents for a template, in some cases we experienced issues if the annotated text was significantly shorter than the later in the processed documents. We must keep in mind that this is needed for custom document types only, and our results will be affected by the quality of the document layout, for example if the lines of the table are close to each other, not separated by lines can result in worse extraction results. Similarly, the image quality of the document is a factor affecting the extraction results quality if we are to use picture formats."}),"\n",(0,s.jsx)(t.p,{children:"To create a template*, go to the home screen of your instance of the extraction service and click the second button on the left pane called \u201cTemplate\u201d. Here you will have the opportunity to create maintain templates. After the uploaded example document gets processed, you can annotate the data into the schema fields. To annotate press the \u201cAnnotate\u201d button and then press \u201cEdit\u201d on the upper right pane. Use your mouse to select the text data."}),"\n",(0,s.jsx)(t.p,{children:"* In the current version of DIE the template creation process was changed. To assign a document to the template we need to first post the document for extraction manually, assign the schema to it and process it with an empty template. After the processing is done, we need to annotate the data like before and then click on the 'Add to Template' button to add it. The document will be linked to the selected template that we can activate and use."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Template",src:n(6478).Z+"",width:"3386",height:"1416"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Template2",src:n(6161).Z+"",width:"2434",height:"1652"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Template3",src:n(8439).Z+"",width:"3246",height:"1746"})}),"\n",(0,s.jsx)(t.h3,{id:"13-extraction",children:"1.3 Extraction"}),"\n",(0,s.jsx)(t.p,{children:"After we are finished with the needed customizing of our schemas and templates, we are ready to process documents. Each document uploaded will be processed using a schema and a template, these are chosen during the upload of the document for extraction. As mentioned earlier with correct customizing setup we can use the auto detect functionality to assign the template automatically. We can upload a document manually, using the user interface of the extraction service, or programmatically using the services application interface. To upload a document manually go to the home screen of the extraction service and click the \u201c+\u201d button on the upper right pane. After that fill out the required data, document type and schema. You can also assign a template, but it can also be detected automatically with the \u201cdetect automatically\u201d option. As the next step we choose a file and press the \u201cStep2\u201d button that will show you the extraction header fields from the schema. Continue by pressing \u201cStep3\u201d that will show you the extraction line item fields from the schema. After that press \u201cReview\u201d and \u201cConfirm\u201d to finish the process. The document will show up on the home screen and will have the status \u201cPending\u201d. After the status changes to \u201cReady\u201d you can examine the results. Click on the table entry to open the document and press \u201cExtraction Results\u201d button on the upper right pane. Here you can inspect the result and correct them by pressing the \u201cEdit\u201d button. After editing you will have the opportunity to confirm your changes, that also means the document will be locked and it is expected that all the extracted data is 100% correct. You will also have the option to provide your file to SAP for the chance to be included in the training of the extraction AI (this does not mean it will be included in the training data). Each extraction result field displayed also shows the \u201cConfidence\u201d of the result, which means \u201chow good\u201d the extraction is from the AI point of view. Naturally results with low confidence can have correct values and vice versa, however this is not the rule."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Extraction",src:n(2410).Z+"",width:"2116",height:"1756"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Extraction",src:n(2905).Z+"",width:"3196",height:"1418"})}),"\n",(0,s.jsx)(t.h2,{id:"2-ubc",children:"2. UBC"}),"\n",(0,s.jsx)(t.h3,{id:"21-setup",children:"2.1 Setup"}),"\n",(0,s.jsxs)(t.p,{children:["The setup you have to prepare will be dependent on your concrete implementation and usage of different UBC building blocks. However our main focus here should remain the setup of the DIE connection. Here we will need certain data from the service key of the Document Information Extraction, this could be provided by your IT support team. Please use the mapping exapmle below to map the correct fields into the report that will set up the connection customizing automatically. The report can be found under ",(0,s.jsx)(t.code,{children:"/UBC/DIE_TASK_CONFIG_PROXY"})," or execute the DIE part of the ",(0,s.jsx)(t.code,{children:"/UBC/DIE_MAIL_SETUP"})," task list. In more complicated usecases we can provide a task list tailored to your needs."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Key",src:n(313).Z+"",width:"476",height:"896"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Report",src:n(712).Z+"",width:"3420",height:"1258"})}),"\n",(0,s.jsxs)(t.p,{children:["With this completed you are ready to use the DIE functionalities with one of the standard solutions, or to develop your own solution using the ",(0,s.jsx)(t.code,{children:"/UBC/CL_DIE_PROXY"})," class as you starting point."]}),"\n",(0,s.jsx)(t.h3,{id:"21-pre-extraction-processing",children:"2.1 Pre extraction processing"}),"\n",(0,s.jsxs)(t.p,{children:["Pre extraction processing is everything that happens before the extraction service is called. Here we stay completaly flexible with our UBC.REST, UBC.MQTT and UBC.FLOW implementations, to get and prepare the documents for extraction. For a more concrete example of how a pre extraction process could look like you could refer to the ",(0,s.jsx)(t.a,{href:"#31-pre-extraction-processing",children:"QEASY"})," implementation."]}),"\n",(0,s.jsx)(t.h3,{id:"22-post-extraction-processing",children:"2.2 Post extraction processing"}),"\n",(0,s.jsx)(t.p,{children:"Post extraction processing is everything that happens after the extraction of unstructured data from the document is received. As the first step a validity check will be executed over the extraction result checking for the minimum acceptable confidence of the results. This value will be set as part of business object setup supporting your process logic. If at least one of the extraction fields is to be of smaller confidence, then the required minimum the processing will stop with an error message and a manual correction, or confirmation will be needed from the assigned users. After the corrections, the processing may continue."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Confidence",src:n(266).Z+"",width:"1418",height:"254"})}),"\n",(0,s.jsxs)(t.p,{children:["Here custom implementations can be injected into the process, that will determine what should be done with the results. UBC provides standard implementation for certain usecases for example mapping into ",(0,s.jsx)(t.code,{children:"QALITY02"})," IDoc structure. The logic to be executed can be defined in a post processing class, that will be linked to the extraction with a schema id and a template id. This way the process dynamically determines what logic is to be used for the current document. The assignement of the implementing class is to be maintained using the maintenance view ",(0,s.jsx)(t.code,{children:"/UBC/DIE_PR_LK_V"})," or accessed from ",(0,s.jsx)(t.code,{children:"/n/UBC_CUSTOMIZING"})," by the ",(0,s.jsx)(t.code,{children:"Link Template to Implementation"})," shortcut."]}),"\n",(0,s.jsxs)(t.p,{children:["To implement a post processing class it needs to interface ",(0,s.jsx)(t.code,{children:"/UBC/IF_DIE_POST_PROCESSING"})," or inherit from one of the standard UBC implementations of it. With the redefinition/implementation of the method ",(0,s.jsx)(t.code,{children:"/UBC/IF_DIE_POST_PROCESSING~process_result"})," the custom processing logic will be called."]}),"\n",(0,s.jsx)(t.p,{children:"If a manual correction is needed in the extraction results, the document button can be used for each message in the IO monitor. This opens the browser and takes the user directly to the concrete document, where the results can be manually changed and saved. On user save all of the fields will have confidence of 1 meaning 100% because they were edited by a user thus should be correct. After the changes are saved the message can be restarted in the IO monitor, this will result in fetching the extraction results again (with the updated values) and continue the processing with the next step."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"DIE_JUMP",src:n(7542).Z+"",width:"2134",height:"434"})}),"\n",(0,s.jsx)(t.p,{children:"We have two more button options available for each message. These can be used to quickly access other objects or screens to be able to monitor your process in an efficient way."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"EMAIL_JUMP",src:n(4403).Z+"",width:"2058",height:"438"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"QEASY_JUMP",src:n(9367).Z+"",width:"2060",height:"424"})}),"\n",(0,s.jsx)(t.h2,{id:"3-qeasy-implementation",children:"3. QEASY implementation"}),"\n",(0,s.jsxs)(t.p,{children:["The following segment describes the process and components used by the QEASY implementation with ",(0,s.jsx)(t.a,{href:"/ubc-docs-ghpages/",children:"UBC"}),". This implementation takes place in three different system landscapes. The entire process starts with an inbound process, in our case this is an email received in a designated inbox with an attachment containing the certificate.\nThe emails are periodically read out of the inbox, marked as read and moved to a \u201cprocessed\u201d folder.\nAfter the initial pre-processing of the data, it is sent to the SAP Business Technology Platform where an instance of the Document Information Extraction service is running. The service extracts the text data from the unstructured document and the results are queried by UBC for further processing. After the extracted data is received by UBC a validity check happens that checks the quality of the extracted data. In case the confidence on an extraction is low a responsible person will be notified to correct and confirm the data manually for the processing to continue. The last step is the post extraction processing, which is customer specific logic to be executed with the extracted data. In our case the extracted data will be mapped to an IDoc of type \u201cQALITY02\u201d, that will be used as an input for \u201cQEASY\u201d for automatic test lot creation. An overview of the IDoc data and the posted data will be visualized also in the \u201cQEASY Cockpit\u201d (transaction: /n/QEASY/LFCER). The use of this implementation is promising the automatization of multiple manual tasks as well as a first step toward the use of artificial intelligence and cloud tools in practice."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Process",src:n(6247).Z+"",width:"1359",height:"849"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Flow",src:n(1801).Z+"",width:"1356",height:"849"})}),"\n",(0,s.jsx)(t.h3,{id:"31-pre-extraction-processing",children:"3.1 Pre extraction processing"}),"\n",(0,s.jsxs)(t.p,{children:["For this usecase the standard UBC implementation of ",(0,s.jsx)(t.a,{href:"/ubc-docs-ghpages/integrations/O365Mail/documentation",children:"Microsoft Mail"})," is used. The first step of the process is reading emails from an inbox and getting the attachment of the email. Attached should be only one attachment at the time, because we will start one workflow per email. The attachment should be of format pdf. The emails to be processed must be in unread state, that differentiates the ones to be processed. After the workflow starts for the email and its attachment the status is changed to read and is moved to a different folder in the mailbox."]}),"\n",(0,s.jsx)(t.h3,{id:"32-extraction",children:"3.2 Extraction"}),"\n",(0,s.jsx)(t.p,{children:"The result should be mapped into an IDoc structure of type \u201cQALITY02\u201d and for that we will always need to extract certain fields from the certificate regardless of the type or layout. These fields can make their way into a schema belonging to this process. The fields are the following:"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Header Fields"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Suggested Field Name"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Type"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Order number"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"PO_Num"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"string"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Item number"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"PO_Item_Num"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"string"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Material number"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Material"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"string"})]})]})]}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Line Item Fields"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Suggested Field Name"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Type"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Name of the characteristic"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Characteristic_Name"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"string"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Value of the characteristic"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Value"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"string"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Unit of measurement"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"UOM"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"string"})]})]})]}),"\n",(0,s.jsx)(t.h3,{id:"33-post-extraction-processing",children:"3.3 Post extraction processing"}),"\n",(0,s.jsx)(t.p,{children:"As the last step the IDoc will be used to trigger QEASY for inspection lot creation with integrated validity checks as standard.\nThis mapping is handled by a post processing ABAP class that dictates how should the extraction results be mapped into the IDoc. A class can be assigned to a template that way we have the flexibility of creating different mappings for different documents, for example one class could create multiple IDocs from one document, while others just one, or custom logic could be defined to look up additional data not found in the document but is needed for the processes further down the line."}),"\n",(0,s.jsx)(t.p,{children:"The two buttons in the IO monitor in this case are already pre configured. The first 'Message' takes the user into the mailbox and directly to the mail that is being processed. The second one 'SAP Object' takes the user to the QEASY cockpit where the created IDoc/IDocs and the inspection lot creation can be monitored."}),"\n",(0,s.jsx)(t.h4,{id:"331-idoc-creation",children:"3.3.1 IDoc creation"}),"\n",(0,s.jsxs)(t.p,{children:["The QEASY implementation by default provides a default post processing class",(0,s.jsx)(t.code,{children:"/UBC/CL_DIE_POST_PROC_CERT_STD"}),", that creates a single IDoc from the extraction results. It expects all of the mandatory fields to be found in the extraction results (under the same structure and names as in the suggested naming convention), and performs no checks over the created IDoc. If a decision is made that a different naming convention is to be used, or a document provides the data in different format, a new class can be created that needs to interface ",(0,s.jsx)(t.code,{children:"/UBC/IF_DIE_POST_PROCESSING"})," or inheriting from ",(0,s.jsx)(t.code,{children:"/ubc/cl_die_post_proc"})," Here the method ",(0,s.jsx)(t.code,{children:"process_result"})," needs to be implemented that should create IDocs and return the required parameters. If we want to reuse some of the existing functionalities, then the new class could inherit ",(0,s.jsx)(t.code,{children:"/UBC/CL_DIE_POST_PROC_CERT_STD"})," and redefine the some of the methods. For example method ",(0,s.jsx)(t.code,{children:"set_data"})," could be redefined for a completely new logic for IDoc mapping from results, or methods like ",(0,s.jsx)(t.code,{children:"get_material_num"})," could be redefined to keep existing mapping logic just change certain parts like variable name of extracted fields or some additional logic with the extracted data.\nIf the class is completed it can be assigned to a schema and optionally also a template, linking one or multiple schema/template ids to an implementing class. The links are stored in the table ",(0,s.jsx)(t.code,{children:"/UBC/DIE_PR_LINK"})," and entries can be maintained using the maintenance view ",(0,s.jsx)(t.code,{children:"/UBC/DIE_PR_LK_V"})," or accessed from ",(0,s.jsx)(t.code,{children:"/n/UBC_CUSTOMIZING"})," by the ",(0,s.jsx)(t.code,{children:"Link Template to Implementation"})," shortcut. During the post processing the used template and schema is checked from the received extraction results and based on that an implementation is fetched."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Template link Customizing",src:n(9138).Z+"",width:"2484",height:"846"}),"\n",(0,s.jsx)(t.img,{alt:"Template link Entries",src:n(7690).Z+"",width:"976",height:"902"})]}),"\n",(0,s.jsx)(t.h4,{id:"332-idoc-mapping",children:"3.3.2 IDoc mapping"}),"\n",(0,s.jsx)(t.p,{children:"The IDoc structure in the postprocessing steps will be filled with the following data. The data in the IDoc will be a mixture of system variables, data queried from the email and our extraction results."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Segment type"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Element"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"Value"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDK03"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"IDDAT"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"constant"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDK03"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"DATUM"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Email receive date"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDK03"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"UZEIT"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Email receive time"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDK02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"QUALF"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"constant"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDK02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"BELNR"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"PO number (from extr.)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDK02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"DATUM"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Current date"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDK02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"UZEIT"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Current time"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP19"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"QUALF"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"constant"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP19"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"IDTNR"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Material number from PO*"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"QUALF"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"constant"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"BELNR"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"PO number (from extr.)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"ZEILE"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"PO item number (from extr.)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"DATUM"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Current datum"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP02"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"UZEIT"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Current time"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP03"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"IDDAT"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"constant"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP03"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"DATUM"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Email receive date"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1EDP03"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"UZEIT"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Email receive time"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1CCI01"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"CHARACTERISTIC_NAME"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Characteristic name per char.** (from extr.)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1MEA01"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"INSPECTION_DATA_TYPE"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"constant"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1MEA01"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"VALUE"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Characteristic value per char.*** (from extr.)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1MEA01"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"INSPECTED_QUANTITY"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"constant"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"E1MEA01"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"NUMBER_OF_SAMPLES"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"constant"})]})]})]}),"\n",(0,s.jsxs)(t.p,{children:["* in the base class conversion ",(0,s.jsx)(t.code,{children:"CONVERSION_EXIT_MATN1_INPUT"})," is used on the extracted value to be ",(0,s.jsx)(t.strong,{children:"correctly processed by QEASY"})]}),"\n",(0,s.jsxs)(t.p,{children:["** in the base class conversion to ",(0,s.jsx)(t.strong,{children:"all upper case"})," is used on the extracted value to be **correctly processed by QEASY**"]}),"\n",(0,s.jsxs)(t.p,{children:["*** in the base class we replace ",(0,s.jsx)(t.strong,{children:"decimal point"})," with ",(0,s.jsx)(t.strong,{children:"comma"})," in the extracted values to be **correctly processed by QEASY**"]})]})}function h(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8439:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Add_to_template-40a2ec1c6efb6107e928c0d08af91e88.png"},266:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Confidence_error-bea5f4830636c55cf4fe2777620d0837.png"},7542:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/DIE_jump-b587dcebcf6bb5a98f6067512f351285.png"},4403:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Email_jump-a7caa08feff52a38e05a0621cd1eeac4.png"},2410:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Extractio_upload-c2c7949b07b4548179c20085d2576ae7.png"},2905:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Extraction-b8569becbf8bceaaad03cda9d8a446c2.png"},1801:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Flow_chart-6329f30894a7058bfa7a44753a6547b0.png"},9367:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Lfcer_jump-898ae1eecd85d4637854a6e9afd266a9.png"},6247:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Proces-f958316af35c95b1163ffdef50fc3baa.png"},712:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Proxy-ae7d19c4c46c9c8b458aa739d3d28492.png"},313:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Proxy_from_key-5ccb2a0cef600e77947e9009ee72cdf6.png"},6687:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Schema_UBC-1057521230649de97f1d55c258988785.png"},6478:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Template-ddee6e35c8b9c6fdeb860108a507ae38.png"},7690:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Template_implementation_link-a55b57c6bec759e3c576a74d4cc2c367.png"},9138:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Template_implementation_link_v-2c72f155baa1ade2b0693913137d9fc4.png"},6161:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/Template_mark_results-bb6f34cfbb9c7679e9c7ef9236641c24.png"},1151:(e,t,n)=>{n.d(t,{Z:()=>o,a:()=>r});var s=n(7294);const i={},a=s.createContext(i);function r(e){const t=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);